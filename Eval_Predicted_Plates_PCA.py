import os
import sys
sys.path.append('/projects/')
import pandas as pd
import numpy as np
import cv2
from PIL import Image
import os
import shutil
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from scipy.spatial.distance import cosine
from sklearn.decomposition import PCA

plate = "Plate_B"
model = "AdaGN-Target_CG-None_unlabelled"

# Ground Truth Plate
GT_dir = f"/projects/img/GAN_CP/PAPER_3/Palette-Image-to-Image-Diffusion-Models-main/{plate}/Ground_Truth/"
# Predicted Plate
Predicted_dir = f"/projects/img/GAN_CP/PAPER_3/Palette-Image-to-Image-Diffusion-Models-main/{plate}/{model}/"
# Cellprofuler Features:
Feature_path = f"/projects/img/GAN_CP/PAPER_3/Palette-Image-to-Image-Diffusion-Models-main/{plate}/Combined_standardized_featureselect_{model}/"



#Combined_standardized_featureselect_AdaGN-None_CG-None
#Combined_standardized_featureselect_AdaGN-Pert_CG-None
#Combined_standardized_featureselect_AdaGN-Pert_CG-None_unlabelled
#Combined_standardized_featureselect_AdaGN-Target_CG-None <<<<<<<<<<<<<<<<<<<<<<<<< don't have this yet, have re-run
#Combined_standardized_featureselect_AdaGN-Target_CG-None_unlabelled



###### TABLE 2: Feature Evaluation ######

#Load features generated by "Process_features_with_annotations.py" script

All_feats = pd.read_csv(f'{plate}_annotated_features_{model}_all.csv')
#Active_feats = pd.read_csv(f'{plate}_annotated_features_{model}_actives.csv')
#No_controls_feats = pd.read_csv(f'{plate}_annotated_features_{model}_no_controls.csv')
#DMSO_feats = pd.read_csv(f'{plate}_annotated_features_{model}_controls.csv')




def PCA_function(feat):
    GT_All_feats = feat[~feat["Metadata_Plate"].str.contains("Pred_")]
    Pred_All_feats = feat[feat["Metadata_Plate"].str.contains("Pred_")]
    
    GT_All_feats = GT_All_feats.reset_index(drop=True)
    
    Pred_All_feats = Pred_All_feats.reset_index(drop=True)
    
    
    first_columns = GT_All_feats.iloc[:,1:6]
    first_columns = first_columns.reset_index(drop=True)
    print(first_columns)
    GT_All_feats = GT_All_feats.iloc[:,6:]
    pca = PCA(n_components=50)
    df_pca_GT = pca.fit_transform(GT_All_feats)
    GT_All_feats = pd.DataFrame(df_pca_GT)
    GT_All_feats = GT_All_feats.reset_index(drop=True)
    return_concat = pd.concat([first_columns, GT_All_feats], axis=1)
    print(return_concat)
    
    first_columns_ = Pred_All_feats.iloc[:,1:6]
    first_columns_ = first_columns_.reset_index(drop=True)
    print(first_columns_)
    Pred_All_feats = Pred_All_feats.iloc[:,6:]
    pca_ = PCA(n_components=50)
    df_pca_Pred = pca_.fit_transform(Pred_All_feats)
    Pred_All_feats = pd.DataFrame(df_pca_Pred)
    Pred_All_feats = Pred_All_feats.reset_index(drop=True)
    return_concat_ = pd.concat([first_columns_, Pred_All_feats], axis=1)
    print(return_concat_)
    
    return_concat_out = pd.concat([return_concat, return_concat_], axis=0)
    
    print(return_concat_out)
    return return_concat_out
    


All_feats = PCA_function(All_feats)
#Active_feats = PCA_function(Active_feats)
#No_controls_feats = PCA_function(No_controls_feats)
#DMSO_feats = PCA_function(DMSO_feats)




#Splitter

def SplitGTandPred(feats):
    GT_All_feats = feats[~feats["Metadata_Plate"].str.contains("Pred_")]
    Pred_All_feats = feats[feats["Metadata_Plate"].str.contains("Pred_")]
    GT_All_feats_values = GT_All_feats.iloc[:,5:]
    GT_All_feats_values = GT_All_feats_values.reset_index(drop=True)
    Pred_All_feats_values = Pred_All_feats.iloc[:,5:]
    Pred_All_feats_values = Pred_All_feats_values.reset_index(drop=True)
    return GT_All_feats_values, Pred_All_feats_values

# Calculate Feature Correlations for all features

def Calculate_Feature_Correlation(feats):
    GT_All_feats_values, Pred_All_feats_values = SplitGTandPred(feats)
    Feature_correlations = Pred_All_feats_values.corrwith(GT_All_feats_values, axis = 0)
    return(np.mean(Feature_correlations))
    

# Calculate Mean Distance (in feature space) to matching target

def Mean_Cosine_Distance_to_matching_target(feats):
    unique_targets = feats["target"].unique()
    cosine_dists = []
    for target in unique_targets:
        target_rows = feats[feats["target"] == target]
        target_features = target_rows.drop(["Metadata_Well","Metadata_broad_sample","pert_iname","target","Metadata_Plate"], axis=1)
        target_features = target_features.reset_index(drop=True)
        target_features = target_features.iloc[:,1:]
        for i in range(target_features.shape[0]):
            f1 = target_features.iloc[i, :]
            for j in range(target_features.shape[0]):
                if i == j:
                    continue
                f2 = target_features.iloc[j, :]
                cosine_dist = cosine(f1, f2)
        cosine_dists.append(cosine_dist)
    mean_cosine_distance = np.mean(cosine_dists)
    std_cosine_distance = np.std(cosine_dists)
    return mean_cosine_distance, std_cosine_distance

# 1NN function:

def classify_1nn(df_values, df_class, index):
  min_dist = float("inf")
  test_row = df_values.iloc[index,:]
#  print(test_row)
  predicted_class = None
  for i, row in df_values.iterrows():
    if i == index:
        pass
    else:
        dist = cosine(test_row, row)
        if dist < min_dist:
          min_dist = dist
          predicted_class_row = df_class.iloc[i,:]
          predicted_class = predicted_class_row["target"]
  return predicted_class

# Calculate NSC matching (Equivalent to 1NN matching for Target2)

def NSC_match_GT(feats):
      GT_All_feats = feats[~feats["Metadata_Plate"].str.contains("Pred_")]
      GT_All_feats = GT_All_feats.reset_index(drop=True)   
      GT_All_feats_values = GT_All_feats.iloc[:,5:]
      GT_All_feats_values = GT_All_feats_values.reset_index(drop=True)
      GT_All_feats["predicted_target"] = None
      for i, row in GT_All_feats_values.iterrows():
          predicted_class = classify_1nn(GT_All_feats_values, GT_All_feats, i)
          GT_All_feats.loc[i, "predicted_target"] = predicted_class
          a = GT_All_feats[["target", "predicted_target"]]
      count = 0
      for i, row in a.iterrows():
          if row["target"] == row["predicted_target"]:
              count += 1
          else:
              count += 0         
      return a, count#/len(a)
  
    
def NSC_match_Pred(feats):
      Pred_All_feats = feats[feats["Metadata_Plate"].str.contains("Pred_")]
      Pred_All_feats = Pred_All_feats.reset_index(drop=True)
      Pred_All_feats_values = Pred_All_feats.iloc[:,5:]
      Pred_All_feats_values = Pred_All_feats_values.reset_index(drop=True)
      Pred_All_feats["predicted_target"] = None
      for i, row in Pred_All_feats_values.iterrows():
          predicted_class = classify_1nn(Pred_All_feats_values, Pred_All_feats, i)
          Pred_All_feats.loc[i, "predicted_target"] = predicted_class
          a = Pred_All_feats[["target", "predicted_target"]]          
      count = 0
      for i, row in a.iterrows():
          if row["target"] == row["predicted_target"]:
              count += 1
          else:
              count += 0
      return a, count#/len(a)


# Praveen Metric:search GT space for a match using the predicted actives (only)
#	- praveen wants list of wells which match to ground truth
#	- he can make a list of matching bioloigcal pairs.

def classify_1nn_Praveen(df_values, GT_values, df_class, index):
  min_dist = float("inf")
  test_row = df_values.iloc[index,:]
  predicted_class = None
  for i, row in GT_values.iterrows():
    if i == index:
        pass
    else:
        dist = cosine(test_row, row)
        if dist < min_dist:
          min_dist = dist
          predicted_class_row = df_class.iloc[i,:]
          predicted_class = predicted_class_row["target"]
  return predicted_class


def Praveen_Function(feats):
    GT_All_feats = feats[~feats["Metadata_Plate"].str.contains("Pred_")]
    GT_All_feats = GT_All_feats.reset_index(drop=True)
    GT_All_feats_values = GT_All_feats.iloc[:,6:]
    GT_All_feats_values = GT_All_feats_values.reset_index(drop=True)
    Pred_All_feats = feats[feats["Metadata_Plate"].str.contains("Pred_")]
    Pred_All_feats = Pred_All_feats.reset_index(drop=True)
    Pred_All_feats_values = Pred_All_feats.iloc[:,6:]
    Pred_All_feats_values = Pred_All_feats_values.reset_index(drop=True)
    
    Pred_All_feats["predicted_target"] = None
    for i, row in Pred_All_feats_values.iterrows():
          predicted_class = classify_1nn_Praveen(Pred_All_feats_values, GT_All_feats_values, Pred_All_feats, i)
          Pred_All_feats.loc[i, "predicted_target"] = predicted_class
          a = Pred_All_feats[["target", "predicted_target"]]          
    count = 0
    for i, row in a.iterrows():
          if row["target"] == row["predicted_target"]:
              count += 1
          else:
              count += 0
    return a, count#/len(a)



print("Mean feature correlation between pred and GT")
print(Calculate_Feature_Correlation(All_feats))

GT_All_feats = All_feats[~All_feats["Metadata_Plate"].str.contains("Pred_")]
print(GT_All_feats)
Pred_All_feats = All_feats[All_feats["Metadata_Plate"].str.contains("Pred_")]
print(GT_All_feats)

print("GT mean dist to matching target")
print(Mean_Cosine_Distance_to_matching_target(GT_All_feats))

print("Prediction mean dist to matching target")
print(Mean_Cosine_Distance_to_matching_target(Pred_All_feats))

print(NSC_match_GT(All_feats))
print(NSC_match_Pred(All_feats))

print(Praveen_Function(All_feats))

####### Appendix: ######


# Create Feature Correlation Matrix











### This calculates the correlation between the shared selected features in plates A and B (GT)
### We can also calculate the correlation between predicted A and predicted B (two completely different models to compare reproducibility
#
#GT_all_A = pd.read_csv(f"/projects/img/GAN_CP/PAPER_3/Palette-Image-to-Image-Diffusion-Models-main/Plate_A/Combined_standardized_featureselect_{model}.csv")
#GT_all_B = pd.read_csv(f"/projects/img/GAN_CP/PAPER_3/Palette-Image-to-Image-Diffusion-Models-main/Plate_B/Combined_standardized_featureselect_{model}.csv")
#
#GT_All_feats_A = GT_all_A[GT_all_A["Metadata_Plate"].str.contains("Pred_")]
#GT_All_feats_B = GT_all_B[GT_all_B["Metadata_Plate"].str.contains("Pred_")]
#
#GT_All_feats_A = GT_All_feats_A.iloc[:,5:]
#GT_All_feats_A = GT_All_feats_A.reset_index(drop=True)
#GT_All_feats_B = GT_All_feats_B.iloc[:,5:]
#GT_All_feats_B = GT_All_feats_B.reset_index(drop=True)
#
#
#a = np.intersect1d(GT_All_feats_A.columns, GT_All_feats_B.columns)
##a = np.delete(a,['Metadata_broad_sample', 'Metadata_Well', 'Metadata_concentration'])
#print(len(a))
#
#ab = GT_All_feats_A[a].corrwith(GT_All_feats_B[a], axis = 0)
#print(np.mean(ab))

